input {
  tcp {
    type => "l2tcsv"
    port => 18005
  }
}

filter {
  if [type] == "l2tcsv" {
    csv { 
       separator => ","
       quote_char => "Âª"       # workaround: don't use a quote character as " gives issues if the field contains a "
       columns => ["datetime","timestamp_desc","source","source_long","message","parser","display_name","tag"]
    }
    if [datetime] == "datetime" {
       drop {}  # drop the first line that contains the column names
    }

    date { 
      #match => ["date", "MM/dd/YYYY HH:mm:ss z" ] 
      match => [ "datetime", "MM/dd/YYYY'T'HH:mm:ssZZ", "ISO8601" ] 
    }

    # extract macb info
    
    # Extract filenames
    if [source] == "FILE" {
      grok { 
        break_on_match => false
        match => ["desc", "(:(?<extracted.path>/.*?))?$",
                  "extracted.path", "(?<extracted.filename>[^/]+?)?$",
                  "extracted.filename", "((\.(?<extracted.ext>[^./]+))?)?$" 
                 ] 
      }
    }
    if [source] == "META" {
      grok { 
        break_on_match => false
        match => ["filename", "(:(?<extracted.path>/.*?))?$",
                  "extracted.path", "(?<extracted.filename>[^/]+?)?$",
                  "extracted.filename", "((\.(?<extracted.ext>[^./]+))?)?$" 
                 ] 
      }
    }
    # Extract urls
    if [source] == "WEBHIST" {
      grok { match => ["desc", "Location: (?<extracted.url>.*?)[ $]"] }
    }
    mutate {
      convert => ["inode", "integer",
                  "version", "integer"] 
      lowercase => ["extracted.ext"]
      remove_field => ["short", "date", "time", "timezone"]
    }
  }
}

output { 
  if [type] == "l2tcsv" {
    elasticsearch {
      index => "logstash-l2tcsv"
      hosts => "elasticsearch:9200"
	  user => "elastic"
	  password => "changeme"
	  ecs_compatibility => disabled
    }
  }
}
